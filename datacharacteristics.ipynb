{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": ".deeplearningclass",
   "display_name": ".deeplearningClass",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDataFile(filePath):\n",
    "    try:\n",
    "        dataset = pd.read_csv(filePath)\n",
    "        print(filePath)\n",
    "    except:\n",
    "        print(\"Could not read file\",filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/Lung cancer/lung-cancer.data\n/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/adult/adult.data\n/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/Pittsburgh Bridges/bridges.data\n/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/trains/trains-transformed.data\n/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/arrhythmia/arrhythmia.data\n/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/dermatology/dermatology.data\n/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/ballons/yellow-small+adult-stretch.data\n"
     ]
    }
   ],
   "source": [
    "listofDataFiles={}\n",
    "for path, subdirs, files in os.walk(os.getcwd()+'/datasets'):\n",
    "    for name in files:\n",
    "        if name.endswith('.data'):\n",
    "            listofDataFiles[name]=os.path.join(path, name)\n",
    "\n",
    "for key in listofDataFiles:\n",
    "    readDataFile(listofDataFiles[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readRows(filePath):\n",
    "    try:\n",
    "        dataset = pd.read_csv(filePath)\n",
    "        n = len(dataset.axes[0])\n",
    "        return n\n",
    "    except:\n",
    "        print(\"Can not read rows for\",filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readColumns(filePath):\n",
    "    try:\n",
    "        dataset = pd.read_csv(filePath)\n",
    "        n = len(dataset.axes[1])\n",
    "        return n\n",
    "    except:\n",
    "        print(\"Can not read columns for\",filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countUniqueLabels(filePath):\n",
    "    try:\n",
    "        dataset = pd.read_csv(filePath)\n",
    "        n = dataset.iloc[:, -1].nunique(dropna=False)\n",
    "        return n\n",
    "    except:\n",
    "        print(\"Can not read unique items for\", filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCorrelation(filePath):\n",
    "    sp=p=sn=n=0\n",
    "    try:\n",
    "        dataset = pd.read_csv(filePath)\n",
    "        rows, cols = dataset.shape\n",
    "        corr1 = dataset.corr()\n",
    "\n",
    "        c1 = corr1.abs().unstack()\n",
    "      \n",
    "\n",
    "\n",
    "        for i in c1:\n",
    "            if(i==1):\n",
    "                sp+=1\n",
    "            elif(i==-1):\n",
    "                sn+=1\n",
    "            elif(i>0):\n",
    "                p+=1\n",
    "            else:\n",
    "                n+=1\n",
    "        corrDict = {}\n",
    "        sp=sp/(cols*(cols-1))\n",
    "        corrDict['spCorr'] = sp \n",
    "        p=p/(cols*(cols-1))\n",
    "        corrDict['pCorr'] = p\n",
    "        sn=sn/(cols*(cols-1))\n",
    "        corrDict['snCorr'] = sn \n",
    "        n=n/(cols*(cols-1))\n",
    "        corrDict['nCorr'] = n\n",
    "        return corrDict\n",
    "\n",
    "    except:\n",
    "        print(\"Can not compute correlation for\", filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'spCorr': 0.018483709273182956, 'pCorr': 0.8978696741854637, 'snCorr': 0.0, 'nCorr': 0.03132832080200501}\n",
      "{'spCorr': 0.02857142857142857, 'pCorr': 0.14285714285714285, 'snCorr': 0.0, 'nCorr': 0.0}\n",
      "Can not compute correlation for /home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/Pittsburgh Bridges/bridges.data\n",
      "None\n",
      "Can not compute correlation for /home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/trains/trains-transformed.data\n",
      "None\n",
      "{'spCorr': 0.0033026113671274964, 'pCorr': 0.8487711213517665, 'snCorr': 0.0, 'nCorr': 0.11598822324628776}\n",
      "{'spCorr': 0.02857142857142857, 'pCorr': 0.9428571428571428, 'snCorr': 0.0, 'nCorr': 0.0}\n",
      "Can not compute correlation for /home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/ballons/yellow-small+adult-stretch.data\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "corrDict = {}\n",
    "dataCharacteristics = {}\n",
    "for eachFile in listofDataFiles:\n",
    "   # print(eachFile)\n",
    "    dataCharacteristics[eachFile] = {}\n",
    "    dataCharacteristics[eachFile]['instances'] = readRows(listofDataFiles[eachFile])\n",
    "    dataCharacteristics[eachFile]['attributes'] = readColumns(listofDataFiles[eachFile])\n",
    "    dataCharacteristics[eachFile]['uniqueClasses'] = countUniqueLabels(listofDataFiles[eachFile])\n",
    "    corrDict = computeCorrelation(listofDataFiles[eachFile])\n",
    "    print(corrDict)\n",
    "    if(corrDict):\n",
    "        dataCharacteristics[eachFile].update(corrDict)\n",
    "    #print(corrDict)\n",
    "\n",
    "\n",
    "#for key in dataCharacteristics:\n",
    "  #  print(dataCharacteristics[key]['uniqueClasses'])\n",
    "    #print(dataCharacteristics[key]['attributes'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.json\",\"w\") as f:\n",
    "    json.dump(dataCharacteristics,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(corrDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}