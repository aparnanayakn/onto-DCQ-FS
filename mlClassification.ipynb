{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": ".deeplearningclass",
   "display_name": ".deeplearningClass",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    " #converting string categorical value to numeric categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#feature selection\n",
    "from sklearn import svm\n",
    "\n",
    "from mrmr import mrmr_classif\n",
    "from info_gain import info_gain\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _readCSVFile(filePath):\n",
    "        with open(filePath, 'r', newline='',  encoding='utf-8') as csvfile:\n",
    "            has_header = csv.Sniffer().has_header(csvfile.readline())\n",
    "            csvfile.seek(0)  # Rewind.\n",
    "            dialect = csv.Sniffer().sniff(csvfile.read(), delimiters=';,\\t')\n",
    "            csvfile.seek(0) \n",
    "            reader = csv.reader(csvfile, dialect)\n",
    "            if(has_header):\n",
    "                next(reader)  # Skip header row.\n",
    "            dataset = pd.DataFrame(reader)\n",
    "        return dataset\n",
    "        #print(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _readExcel(filePath):\n",
    "    dataset = pd.read_excel(filePath)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_csv(fname):\n",
    "    if fname.endswith((\".data\", \".csv\")):\n",
    "        return _readCSVFile(fname)\n",
    "    elif fname.endswith((\".xlsx\", \".xls\")):\n",
    "        return _readExcel(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _assumption1categorical(df):\n",
    "    likely_cat = []\n",
    "    for idx, var in enumerate(df.columns):\n",
    "        if(1.*df[var].nunique()/df[var].count() < 0.05): #or some other threshold\n",
    "            likely_cat.append(idx)\n",
    "    return likely_cat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _assumption2categorical(df):\n",
    "    top_n = 10 \n",
    "    likely_cat = []\n",
    "    for idx, var in enumerate(df.columns):\n",
    "        if(1.*df[var].value_counts(normalize=True).head(top_n).sum() > 0.8): #or some other threshold\n",
    "            likely_cat.append(idx)\n",
    "    return likely_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertstrtointcategory(df): \n",
    "    le = LabelEncoder()\n",
    "    ass1 = _assumption1categorical(df) \n",
    "    ass2 = _assumption2categorical(df)\n",
    "\n",
    "    #extract only columns that belong to \n",
    "    commonidx = (list(set(ass1) | set(ass2)))\n",
    "\n",
    "    for i in commonidx:\n",
    "        df.iloc[:,i] = le.fit_transform(df.iloc[:,i])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabels(dataset):\n",
    "    try:\n",
    "        flag = 0\n",
    "        #dataset = custom_csv(filePath)\n",
    "        #dataset = pd.read_csv(\"/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/iris/iris.data\")\n",
    "        n = dataset.iloc[:, -1].nunique(dropna=False)\n",
    "        perc = dataset.iloc[:, -1].value_counts(normalize=True)*100\n",
    "        if(len(perc) > len(dataset.iloc[:, 0].value_counts(normalize=True)*100)):  #checking whether 1st column is label\n",
    "            n=dataset.iloc[:, 0].nunique(dropna=False)\n",
    "            flag = 1\n",
    "        if(flag == 1):\n",
    "            return dataset.iloc[:, 0]\n",
    "        else:\n",
    "            return dataset.iloc[:,-1]\n",
    "    except:\n",
    "        print(\"Can not read last column items for\", filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getindependentVariables(dataset):\n",
    "    try:\n",
    "        flag = 0\n",
    "        #dataset = custom_csv(filePath)\n",
    "        n = dataset.iloc[:, -1].nunique(dropna=False)\n",
    "        perc = dataset.iloc[:, -1].value_counts(normalize=True)*100\n",
    "        if(len(perc) > len(dataset.iloc[:, 0].value_counts(normalize=True)*100)):  #checking whether 1st column is label\n",
    "            n=dataset.iloc[:, 0].nunique(dropna=False)\n",
    "            flag = 1\n",
    "        if(flag == 1):\n",
    "            return dataset.iloc[:, 1:]\n",
    "        else:\n",
    "            return dataset.iloc[:,:-1]\n",
    "    except:\n",
    "        print(\"Can not independent variabless for\", filePath)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectFeatures(X, impFeatures, threshold):\n",
    "    X_new = pd.DataFrame()\n",
    "    for idx, value in enumerate(impFeatures):\n",
    "        if(value > threshold):\n",
    "            X_new = pd.concat((X_new, X.iloc[:, idx]), axis=1)\n",
    "    return X_new    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutualInfo(X,Y):\n",
    "    return mutual_info_classif(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gainRatio(X,Y):\n",
    "    info_gain_ratio_values = []\n",
    "    for idx, col in X.iteritems():\n",
    "        info_gain_ratio_values.append(info_gain.info_gain_ratio(col.values, Y.values.tolist()))\n",
    "    return info_gain_ratio_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniqueClasses(Y):\n",
    "    return len(Y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyKNN(X,Y, fs):\n",
    "    if(fs == \"MI\"):\n",
    "      impF = mutualInfo(X,Y)\n",
    "    elif(fs == \"GR\"):\n",
    "      impF = gainRatio(X,Y)\n",
    "    elif(fs == \"mrmr\"):\n",
    "      impF = mrmr_classif(X, Y, K = 10)\n",
    "    X_new = selectFeatures(X, impF, 0.368)\n",
    "    print(X_new.shape[1])  # add this as a feature ; one of the evaluation criteria\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X_new,Y,test_size=0.25,random_state=0)\n",
    "    neighbors = uniqueClasses(Y)\n",
    "    knn=KNeighborsClassifier(n_neighbors=neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred= knn.predict(X_test)\n",
    "    target_names = (list(range(uniqueClasses(Y))))\n",
    "    for index, item in enumerate(target_names):\n",
    "      target_names[index] = str(item)\n",
    "   # TN = cnf_matrix.values.sum() - (FP + FN + TP) \n",
    "    #tp, fn, fp, tn = metrics.confusion_matrix(y_test, y_pred, labels = getLabels(filePath)).ravel()\n",
    "    report = classification_report(y_test, y_pred,  target_names=target_names, output_dict=True)\n",
    "    return pd.DataFrame(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyNB(X,Y, fs):\n",
    "    if(fs == \"MI\"):\n",
    "      impF = mutualInfo(X,Y)\n",
    "    elif(fs == \"GR\"):\n",
    "      impF = gainRatio(X,Y)\n",
    "    elif(fs == \"mrmr\"):\n",
    "      impF = mrmr_classif(X, Y, K = 10)\n",
    "    X_new = selectFeatures(X, impF, 0.368)\n",
    "    print(X_new.shape[1])  # add this as a feature ; one of the evaluation criteria\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X_new,Y,test_size=0.25,random_state=0)\n",
    "    neighbors = uniqueClasses(Y)\n",
    "    clf = MultinomialNB() \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred= clf.predict(X_test)\n",
    "    target_names = (list(range(uniqueClasses(Y))))\n",
    "    for index, item in enumerate(target_names):\n",
    "      target_names[index] = str(item)\n",
    "   # TN = cnf_matrix.values.sum() - (FP + FN + TP) \n",
    "    #tp, fn, fp, tn = metrics.confusion_matrix(y_test, y_pred, labels = getLabels(filePath)).ravel()\n",
    "    report = classification_report(y_test, y_pred,  target_names=target_names, output_dict=True)\n",
    "    return pd.DataFrame(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifySVM(X,Y, fs):\n",
    "    if(fs == \"MI\"):\n",
    "      impF = mutualInfo(X,Y)\n",
    "    elif(fs == \"GR\"):\n",
    "      impF = gainRatio(X,Y)\n",
    "    elif(fs == \"mrmr\"):\n",
    "      impF = mrmr_classif(X, Y, K = 10)\n",
    "    X_new = selectFeatures(X, impF, 0.368)\n",
    "    print(X_new.shape[1])  # add this as a feature ; one of the evaluation criteria\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X_new,Y,test_size=0.25,random_state=0)\n",
    "    neighbors = uniqueClasses(Y)\n",
    "    clf = svm.SVC(kernel='linear', random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred= clf.predict(X_test)\n",
    "    target_names = (list(range(uniqueClasses(Y))))\n",
    "    for index, item in enumerate(target_names):\n",
    "      target_names[index] = str(item)\n",
    "   # TN = cnf_matrix.values.sum() - (FP + FN + TP) \n",
    "    #tp, fn, fp, tn = metrics.confusion_matrix(y_test, y_pred, labels = getLabels(filePath)).ravel()\n",
    "    report = classification_report(y_test, y_pred,  target_names=target_names, output_dict=True)\n",
    "    return pd.DataFrame(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4d100e2d0b35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#report should be dataset specific - each output file is for a single dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmacro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"avg,weighted\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"avg,\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CA,\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FS,\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"->\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"such\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"4*9\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"in\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"each\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "#report should be dataset specific - each output file is for a single dataset\n",
    "\n",
    ",0,1,2,accuracy,macro avg,weighted avg, CA, FS, %features  -> such 4*9 rows in each file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/numeric datasets/wine/wine.data'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-057d03d93dce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfsa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"MI\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"GR\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"mrmr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetindependentVariables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetLabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-8c740c5d7a49>\u001b[0m in \u001b[0;36mcustom_csv\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcustom_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_readCSVFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".xlsx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".xls\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_readExcel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-1852e31748d7>\u001b[0m in \u001b[0;36m_readCSVFile\u001b[0;34m(filePath)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_readCSVFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m             \u001b[0mhas_header\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSniffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mcsvfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Rewind.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mdialect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSniffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msniff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';,'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/numeric datasets/wine/wine.data'"
     ]
    }
   ],
   "source": [
    "#working FCBF\n",
    "import import_ipynb\n",
    "import fastC\n",
    "\n",
    "url = '/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/numeric datasets/1. Wine/wine.data'\n",
    "df = pd.read_csv(url, index_col=False)\n",
    "X = df.iloc[: , 1:]\n",
    "Y = df.iloc[:, 0]\n",
    "t = 0.05\n",
    "sub = []\n",
    "sub = (fastC.fcbf(X,Y,t))\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(element) -> bool:\n",
    "    try:\n",
    "        float(element)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greatestNegative(columnValues):\n",
    "    result = 0\n",
    "    for number in columnValues:\n",
    "        if(is_float(number)):\n",
    "            if(float(number) < 0):\n",
    "                if(float(number) < float(result)):\n",
    "                    result = number\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findmin(df):\n",
    "    result = []\n",
    "    for c in df:\n",
    "        result.append(greatestNegative(df[c]))\n",
    "    return min(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addMintoDF(df, minElement):\n",
    "    for c in df:\n",
    "        df[c] = pd.to_numeric(df[c]) + minElement\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(clf, X, Y, fs):\n",
    "    print(type(X))\n",
    "    if(fs == \"MI\"):\n",
    "      impF = mutualInfo(X,Y)\n",
    "    elif(fs == \"GR\"):\n",
    "      impF = gainRatio(X,Y)\n",
    "    elif(fs == \"mrmr\"):\n",
    "      impF = mrmr_classif(X, Y, K = 10)\n",
    "    elif(fs == \"fcbf\")\n",
    "      impF =\n",
    "    if(clf.__class__.__name__ == \"MultinomialNB\"):\n",
    "        m = findmin(X)\n",
    "        X =  addMintoDF(X, m)\n",
    "    X_new = selectFeatures(X, impF, 0.368)\n",
    "    if(len(X_new) == 0 ):\n",
    "        X_new = selectFeatures(X, impF, np.mean(impF))\n",
    "    print(len(X_new), len(Y))  # add this as a feature ; one of the evaluation criteria\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X_new,Y,test_size=0.25,random_state=0)\n",
    "    neighbors = uniqueClasses(Y)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred= clf.predict(X_test)\n",
    "    target_names = (list(range(uniqueClasses(Y))))\n",
    "    for index, item in enumerate(target_names):\n",
    "      target_names[index] = str(item)\n",
    "   # TN = cnf_matrix.values.sum() - (FP + FN + TP) \n",
    "    #tp, fn, fp, tn = metrics.confusion_matrix(y_test, y_pred, labels = getLabels(filePath)).ravel()\n",
    "    report = classification_report(y_test, y_pred,  target_names=target_names, output_dict=True)\n",
    "    return pd.DataFrame(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "bank-full.csv\n",
      "----------------------\n",
      "SVC\n",
      "GR\n",
      "45211 45211\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "45211 45211\n",
      "*******DONE*********\n",
      "MI\n",
      "45211 45211\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "45211 45211\n",
      "*******DONE*********\n",
      "mrmr\n",
      "45211 45211\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "100%|██████████| 10/10 [00:00<00:00, 11.77it/s]\n",
      "45211 45211\n",
      "*******DONE*********\n",
      "KNeighborsClassifier\n",
      "GR\n",
      "45211 45211\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "45211 45211\n",
      "*******DONE*********\n",
      "MI\n",
      "45211 45211\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "45211 45211\n",
      "*******DONE*********\n",
      "mrmr\n",
      "45211 45211\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "100%|██████████| 10/10 [00:01<00:00,  5.71it/s]\n",
      "45211 45211\n",
      "*******DONE*********\n",
      "LasVegasTripAdvisorReviews-Dataset.csv\n",
      "----------------------\n",
      "SVC\n",
      "GR\n",
      "504 504\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "504 504\n",
      "*******DONE*********\n",
      "MI\n",
      "504 504\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "504 504\n",
      "*******DONE*********\n",
      "mrmr\n",
      "504 504\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "100%|██████████| 10/10 [00:01<00:00,  5.86it/s]\n",
      "504 504\n",
      "*******DONE*********\n",
      "KNeighborsClassifier\n",
      "GR\n",
      "504 504\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "504 504\n",
      "*******DONE*********\n",
      "MI\n",
      "504 504\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "504 504\n",
      "*******DONE*********\n",
      "mrmr\n",
      "504 504\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "100%|██████████| 10/10 [00:00<00:00, 10.07it/s]504 504\n",
      "*******DONE*********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import *\n",
    "#dataset = readCSVFile(\"/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/numeric datasets/wine/wine.data\")\n",
    "#datasethead()\n",
    "\n",
    "classifiers = [ \n",
    "#DecisionTreeClassifier(),\n",
    "#RandomForestClassifier(),\n",
    "#AdaBoostClassifier(),\n",
    "#GradientBoostingClassifier(),\n",
    "#MultinomialNB(),\n",
    "svm.SVC()\n",
    "]\n",
    "\n",
    "listofFiles={}\n",
    "classificationPerfomance={}\n",
    "i=1\n",
    "j=1\n",
    "classificationAlgo = ['knn', 'nb', 'svm']\n",
    "featureAlgo = [\"fcbf\"]\n",
    "for path, subdirs, files in os.walk(os.getcwd()+'/datasets/numeric datasets'):\n",
    "    for name in files:\n",
    "        if name.endswith((\".data\", \".csv\", \".xlsx\", \".xls\")):\n",
    "            listofFiles[name]=os.path.join(path, name)\n",
    "\n",
    "for eachFile in listofFiles:\n",
    "    print(eachFile)\n",
    "    print(\"----------------------\")\n",
    "    classificationPerfomance = {}\n",
    "    dataset = custom_csv(listofFiles[eachFile])\n",
    "    dataset = convertstrtointcategory(dataset)\n",
    "    X = getindependentVariables(dataset)\n",
    "    Y = getLabels(dataset)\n",
    "    n = uniqueClasses(Y)\n",
    "    classifiers.append(KNeighborsClassifier(n))\n",
    "    for clf in classifiers:\n",
    "        j+=1\n",
    "        name = clf.__class__.__name__\n",
    "        print(name)\n",
    "        classificationPerfomance[name] = {}\n",
    "        for eachFSAlgo in featureAlgo:\n",
    "            print(eachFSAlgo)\n",
    "            classificationPerfomance[name][eachFSAlgo] = {}\n",
    "            i+=1\n",
    "            print(len(X), len(Y))\n",
    "            perfMetrics = classify(clf, X,Y, eachFSAlgo)\n",
    "            print(\"*******DONE*********\")\n",
    "            #classificationPerfomance[eachFile]['acc'] = 1\n",
    "    classifiers.pop(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "HCV-Egy-Data2.csv\n"
     ]
    }
   ],
   "source": [
    "for path, subdirs, files in os.walk(os.getcwd()+'/datasets/numeric datasets'):\n",
    "    for name in files:\n",
    "        if name.endswith((\".data\", \".csv\", \".xlsx\")):\n",
    "            listofFiles[name]=os.path.join(path, name)\n",
    "for eachFile in listofFiles:\n",
    "    print(eachFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"dataaccuracy.json\",\"w\") as f:\n",
    "    #dataAccuracy = dataAccuracy.to_json()\n",
    "    json.dump(dataAccuracy,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'{}'"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "json.dumps(dataAccuracy, indent=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-29-0f41813719f4>, line 13)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-0f41813719f4>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    perfMetrics =\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "listofFiles={}\n",
    "classificationPerfomance={}\n",
    "i=1\n",
    "j=1\n",
    "\n",
    "classificationAlgo = {'knn', 'c45', 'nb', 'svm'}\n",
    "featureAlgo = {'relief', 'relieff', 'ig', 'gr', 'fcbf', 'mrmr', 'qbb', 'focus', 'sc'}\n",
    "for path, subdirs, files in os.walk(os.getcwd()+'/datasets/numeric datasets'):\n",
    "    for name in files:\n",
    "        if name.endswith((\".data\", \".csv\", \".xlsx\")):\n",
    "            listofFiles[name]=os.path.join(path, name)\n",
    "\n",
    "perfMetrics =            \n",
    "for eachFile in listofFiles:\n",
    "    classificationPerfomance[eachFile] = {}\n",
    "    for eachClassAlgo in classificationAlgo:\n",
    "        j+=1\n",
    "        classificationPerfomance[eachFile][eachClassAlgo] = {}\n",
    "        for eachFSAlgo in featureAlgo:\n",
    "            fs = \"FS\"+str(i)\n",
    "            classificationPerfomance[eachFile][eachClassAlgo][eachFSAlgo] = {}\n",
    "            i+=1\n",
    "            if(eachClassAlgo == \"kNN\"):\n",
    "                perfMetrics = classifyKNN(listofFiles[eachFile], eachFSAlgo)\n",
    "            #classificationPerfomance[eachFile]['acc'] = 1\n",
    "\n",
    "        i=1\n",
    "    j=1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "\n",
    "dataset = pd.read_csv(\"/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/numeric datasets/heart failure/heart_failure_clinical_records_dataset.csv\")\n",
    "Y = dataset.iloc[:, :1]\n",
    "X = dataset.iloc[:, 1:]\n",
    "#Y = getLabels(\"/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/iris/iris.data\")\n",
    "\n",
    "importantFeaures = mutual_info_classif(X, Y)\n",
    "print((importantFeaures))\n",
    "\n",
    "X_new = SelectPercentile(mutual_info_classif, percentile=70).fit_transform(X, Y)\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=0)\n",
    "\n",
    "fit = model.fit(X_train, y_train)\n",
    "\n",
    "print(X_new.shape)\n",
    "print(X.shape)\n",
    "y_red=fit.predict(X_test)\n",
    "# import the metrics class\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_red)\n",
    "cnf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=3,p=2,metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(y_test,y_pred, average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifaction_report_csv(report):\n",
    "    report_data = []\n",
    "    lines = report.split('\\n')\n",
    "    for line in lines[2:-3]:\n",
    "        row = {}\n",
    "        row_data = line.split('      ')\n",
    "        row['class'] = row_data[0]\n",
    "        row['precision'] = float(row_data[1])\n",
    "        row['recall'] = float(row_data[2])\n",
    "        row['f1_score'] = float(row_data[3])\n",
    "        row['support'] = float(row_data[4])\n",
    "        report_data.append(row)\n",
    "    dataframe = pd.DataFrame.from_dict(report_data)\n",
    "    dataframe.to_csv('classification_report.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = '/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/numeric datasets/wine/wine.data'\n",
    "\n",
    "\n",
    "data = pd.read_csv(url,low_memory=False)\n",
    "x_1 = getindependentVariables(url)\n",
    "data_dia = getLabels(url)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_1, data_dia, test_size=0.3, random_state=42)\n",
    "classifiers = [ \n",
    "KNeighborsClassifier(3),\n",
    "DecisionTreeClassifier(),\n",
    "RandomForestClassifier(),\n",
    "AdaBoostClassifier(),\n",
    "GradientBoostingClassifier(),\n",
    "GaussianNB(),\n",
    "LinearDiscriminantAnalysis() \n",
    "]\n",
    "\n",
    "# Logging for Visual Comparison\n",
    "log_cols = [\"Classifier\", \"Accuracy\", \"Log Loss\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(x_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    print(\"=\" * 30)\n",
    "    print(name)\n",
    "\n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(x_test)\n",
    "    acc = accuracy_score(y_test, train_predictions)\n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "\n",
    "    train_predictions = clf.predict_proba(x_test)\n",
    "    ll = log_loss(y_test, train_predictions)\n",
    "    print(\"Log Loss: {}\".format(ll))\n",
    "\n",
    "    #log_entry = pd.DataFrame([[name, acc * 100, ll]], columns=log_cols)\n",
    "    #log = log.append(log_entry)\n",
    "    #report = classification_report(y_test, train_predictions)\n",
    "    #print(\"log:\",log)\n",
    "    #print(\"=\" * 30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mrmr'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b5f51ac59878>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmrmr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmrmr_classif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mrmr'"
     ]
    }
   ],
   "source": [
    "from mrmr import mrmr_classif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'attrNames'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-aa2201a74085>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0miris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC45\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrNames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'attrNames'"
     ]
    }
   ],
   "source": [
    "from c45 import C45\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "clf = C45(attrNames=iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.9777777777777777\nNumber of mislabeled points out of a total 45 points : 1\n              0          1         2  accuracy  macro avg  weighted avg\nprecision   1.0   1.000000  0.888889  0.977778   0.962963      0.980247\nrecall      1.0   0.952381  1.000000  0.977778   0.984127      0.977778\nf1-score    1.0   0.975610  0.941176  0.977778   0.972262      0.978160\nsupport    16.0  21.000000  8.000000  0.977778  45.000000     45.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "X = getindependentVariables(url)\n",
    "Y = getLabels(url)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=0)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "target_names = (list(range(uniqueClasses(Y))))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (y_test != y_pred).sum()))\n",
    "report = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "pd.DataFrame(report).to_csv('sample.csv')\n",
    "print(pd.DataFrame(report))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column_in_csv_2(input_file, output_file, transform_row, tansform_column_names):\n",
    "    \"\"\" Append a column in existing csv using csv.reader / csv.writer classes\"\"\"\n",
    "    # Open the input_file in read mode and output_file in write mode\n",
    "    with open(input_file, 'r') as read_obj, \\\n",
    "            open(output_file, 'w', newline='') as write_obj:\n",
    "        # Create a DictReader object from the input file object\n",
    "        dict_reader = DictReader(read_obj)\n",
    "        # Get a list of column names from the csv\n",
    "        field_names = dict_reader.fieldnames\n",
    "        # Call the callback function to modify column name list\n",
    "        tansform_column_names(field_names)\n",
    "        # Create a DictWriter object from the output file object by passing column / field names\n",
    "        dict_writer = DictWriter(write_obj, field_names)\n",
    "        # Write the column names in output csv file\n",
    "        dict_writer.writeheader()\n",
    "        # Read each row of the input csv file as dictionary\n",
    "        for row in dict_reader:\n",
    "            # Modify the dictionary / row by passing it to the transform function (the callback)\n",
    "            transform_row(row, dict_reader.line_num)\n",
    "            # Write the updated dictionary or row to the output file\n",
    "            dict_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.9777777777777777\n              0          1         2  accuracy  macro avg  weighted avg\nprecision   1.0   1.000000  0.888889  0.977778   0.962963      0.980247\nrecall      1.0   0.952381  1.000000  0.977778   0.984127      0.977778\nf1-score    1.0   0.975610  0.941176  0.977778   0.972262      0.978160\nsupport    16.0  21.000000  8.000000  0.977778  45.000000     45.000000\n  Unnamed: 0     0          1         2  accuracy  macro avg  weighted avg\n0  precision   1.0   1.000000  0.888889  0.977778   0.962963      0.980247\n1     recall   1.0   0.952381  1.000000  0.977778   0.984127      0.977778\n2   f1-score   1.0   0.975610  0.941176  0.977778   0.972262      0.978160\n3    support  16.0  21.000000  8.000000  0.977778  45.000000     45.000000\n"
     ]
    }
   ],
   "source": [
    "#working column append n classification report\n",
    "X = getindependentVariables(url)\n",
    "Y = getLabels(url)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=0)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "report = classification_report(y_test, y_pred,  target_names=target_names, output_dict=True)\n",
    "#pd.DataFrame(report).to_csv('sample1.csv')\n",
    "print(pd.DataFrame(report))\n",
    "list_of_str = ['First', 'Second', 'Third', 'Fourth']\n",
    "tail_len = 4\n",
    "\n",
    "# The two steps in the description\n",
    "n_rows = sum(1 for row in open('sample1.csv', 'r'))\n",
    "df = pd.read_csv('sample1.csv', skiprows=range(1, n_rows - tail_len))\n",
    "df_rest  = pd.read_csv('sample1.csv', skiprows=range(tail_len, n_rows))\n",
    "\n",
    "print(df)\n",
    "clsss = 'KNN'\n",
    "percFeatures = 12\n",
    "FSA = 'qwe'\n",
    "df['class']=clsss\n",
    "df['percF'] = percFeatures\n",
    "df['FS'] = FSA\n",
    "df\n",
    "f = []\n",
    "pd.concat([df_rest, df]).to_csv('sampe2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "math domain error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-0c42ecb82e71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetindependentVariables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetLabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimpF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo_gain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo_gain_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselectFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimpF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.368\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/info_gain/info_gain.py\u001b[0m in \u001b[0;36minfo_gain_ratio\u001b[0;34m(Ex, a, nan)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;31m# Compute information gain ratio as IG/IV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minfo_gain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mintrinsic_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/info_gain/info_gain.py\u001b[0m in \u001b[0;36mintrinsic_value\u001b[0;34m(Ex, a, nan)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mEx_a_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Ex_a_v_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0msum_v\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEx_a_v\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEx_a_v\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m# Return result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "url = '/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/numeric datasets/wine/wine.data'\n",
    "d = custom_csv(url)\n",
    "\n",
    "X = getindependentVariables(url)\n",
    "Y = getLabels(url)\n",
    "impF = info_gain.info_gain_ratio(X, Y)\n",
    "X_new = selectFeatures(X, impF, 0.368)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_new,Y,test_size=0.25,random_state=0)\n",
    "neighbors = uniqueClasses(Y)\n",
    "knn=KNeighborsClassifier(n_neighbors=neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred= knn.predict(X_test)\n",
    "target_names = (list(range(uniqueClasses(Y))))\n",
    "for index, item in enumerate(target_names):\n",
    "    target_names[index] = str(item)\n",
    "   # TN = cnf_matrix.values.sum() - (FP + FN + TP) \n",
    "    #tp, fn, fp, tn = metrics.confusion_matrix(y_test, y_pred, labels = getLabels(filePath)).ravel()\n",
    "report = classification_report(y_test, y_pred,  target_names=target_names, output_dict=True)\n",
    "print(type(report))\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-d5509f4fc9d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmrmr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmrmr_classif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmrmr_classif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "mrmr_classif(X, Y, K = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          0      1     2      3     4     5      6     7\n",
       "0    1050.0  100.0  11.2   4.38  1.78  2.76  13.20  3.40\n",
       "1    1185.0  101.0  18.6   5.68  2.36  3.24  13.16  3.17\n",
       "2    1480.0  113.0  16.8   7.80  1.95  3.49  14.37  3.45\n",
       "3     735.0  118.0  21.0   4.32  2.59  2.69  13.24  2.93\n",
       "4    1450.0  112.0  15.2   6.75  1.76  3.39  14.20  2.85\n",
       "..      ...    ...   ...    ...   ...   ...    ...   ...\n",
       "172   740.0   95.0  20.5   7.70  5.65  0.61  13.71  1.74\n",
       "173   750.0  102.0  23.0   7.30  3.91  0.75  13.40  1.56\n",
       "174   835.0  120.0  20.0  10.20  4.28  0.69  13.27  1.56\n",
       "175   840.0  120.0  20.0   9.30  2.59  0.68  13.17  1.62\n",
       "176   560.0   96.0  24.5   9.20  4.10  0.76  14.13  1.60\n",
       "\n",
       "[177 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1050.0</td>\n      <td>100.0</td>\n      <td>11.2</td>\n      <td>4.38</td>\n      <td>1.78</td>\n      <td>2.76</td>\n      <td>13.20</td>\n      <td>3.40</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1185.0</td>\n      <td>101.0</td>\n      <td>18.6</td>\n      <td>5.68</td>\n      <td>2.36</td>\n      <td>3.24</td>\n      <td>13.16</td>\n      <td>3.17</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1480.0</td>\n      <td>113.0</td>\n      <td>16.8</td>\n      <td>7.80</td>\n      <td>1.95</td>\n      <td>3.49</td>\n      <td>14.37</td>\n      <td>3.45</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>735.0</td>\n      <td>118.0</td>\n      <td>21.0</td>\n      <td>4.32</td>\n      <td>2.59</td>\n      <td>2.69</td>\n      <td>13.24</td>\n      <td>2.93</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1450.0</td>\n      <td>112.0</td>\n      <td>15.2</td>\n      <td>6.75</td>\n      <td>1.76</td>\n      <td>3.39</td>\n      <td>14.20</td>\n      <td>2.85</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>172</th>\n      <td>740.0</td>\n      <td>95.0</td>\n      <td>20.5</td>\n      <td>7.70</td>\n      <td>5.65</td>\n      <td>0.61</td>\n      <td>13.71</td>\n      <td>1.74</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>750.0</td>\n      <td>102.0</td>\n      <td>23.0</td>\n      <td>7.30</td>\n      <td>3.91</td>\n      <td>0.75</td>\n      <td>13.40</td>\n      <td>1.56</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>835.0</td>\n      <td>120.0</td>\n      <td>20.0</td>\n      <td>10.20</td>\n      <td>4.28</td>\n      <td>0.69</td>\n      <td>13.27</td>\n      <td>1.56</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>840.0</td>\n      <td>120.0</td>\n      <td>20.0</td>\n      <td>9.30</td>\n      <td>2.59</td>\n      <td>0.68</td>\n      <td>13.17</td>\n      <td>1.62</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>560.0</td>\n      <td>96.0</td>\n      <td>24.5</td>\n      <td>9.20</td>\n      <td>4.10</td>\n      <td>0.76</td>\n      <td>14.13</td>\n      <td>1.60</td>\n    </tr>\n  </tbody>\n</table>\n<p>177 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "#working relief\n",
    "import sklearn_relief as relief\n",
    "url = '/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/numeric datasets/wine/wine.data'\n",
    "df = pd.read_csv(url, index_col=False)\n",
    "X = df.iloc[: , 1:]\n",
    "Y = df.iloc[:, 0]\n",
    "r = relief.Relief(\n",
    "    n_features=8 # Choose the best 3 features\n",
    ") # Will run by default on all processors concurrently\n",
    "my_transformed_matrix = r.fit_transform(\n",
    "    X.values,\n",
    "    (Y.values)\n",
    ")\n",
    "pd.DataFrame(my_transformed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          0      1     2      3     4     5      6     7\n",
       "0    1050.0  100.0  11.2   4.38  1.78  2.76  13.20  3.40\n",
       "1    1185.0  101.0  18.6   5.68  2.36  3.24  13.16  3.17\n",
       "2    1480.0  113.0  16.8   7.80  1.95  3.49  14.37  3.45\n",
       "3     735.0  118.0  21.0   4.32  2.59  2.69  13.24  2.93\n",
       "4    1450.0  112.0  15.2   6.75  1.76  3.39  14.20  2.85\n",
       "..      ...    ...   ...    ...   ...   ...    ...   ...\n",
       "172   740.0   95.0  20.5   7.70  5.65  0.61  13.71  1.74\n",
       "173   750.0  102.0  23.0   7.30  3.91  0.75  13.40  1.56\n",
       "174   835.0  120.0  20.0  10.20  4.28  0.69  13.27  1.56\n",
       "175   840.0  120.0  20.0   9.30  2.59  0.68  13.17  1.62\n",
       "176   560.0   96.0  24.5   9.20  4.10  0.76  14.13  1.60\n",
       "\n",
       "[177 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1050.0</td>\n      <td>100.0</td>\n      <td>11.2</td>\n      <td>4.38</td>\n      <td>1.78</td>\n      <td>2.76</td>\n      <td>13.20</td>\n      <td>3.40</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1185.0</td>\n      <td>101.0</td>\n      <td>18.6</td>\n      <td>5.68</td>\n      <td>2.36</td>\n      <td>3.24</td>\n      <td>13.16</td>\n      <td>3.17</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1480.0</td>\n      <td>113.0</td>\n      <td>16.8</td>\n      <td>7.80</td>\n      <td>1.95</td>\n      <td>3.49</td>\n      <td>14.37</td>\n      <td>3.45</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>735.0</td>\n      <td>118.0</td>\n      <td>21.0</td>\n      <td>4.32</td>\n      <td>2.59</td>\n      <td>2.69</td>\n      <td>13.24</td>\n      <td>2.93</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1450.0</td>\n      <td>112.0</td>\n      <td>15.2</td>\n      <td>6.75</td>\n      <td>1.76</td>\n      <td>3.39</td>\n      <td>14.20</td>\n      <td>2.85</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>172</th>\n      <td>740.0</td>\n      <td>95.0</td>\n      <td>20.5</td>\n      <td>7.70</td>\n      <td>5.65</td>\n      <td>0.61</td>\n      <td>13.71</td>\n      <td>1.74</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>750.0</td>\n      <td>102.0</td>\n      <td>23.0</td>\n      <td>7.30</td>\n      <td>3.91</td>\n      <td>0.75</td>\n      <td>13.40</td>\n      <td>1.56</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>835.0</td>\n      <td>120.0</td>\n      <td>20.0</td>\n      <td>10.20</td>\n      <td>4.28</td>\n      <td>0.69</td>\n      <td>13.27</td>\n      <td>1.56</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>840.0</td>\n      <td>120.0</td>\n      <td>20.0</td>\n      <td>9.30</td>\n      <td>2.59</td>\n      <td>0.68</td>\n      <td>13.17</td>\n      <td>1.62</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>560.0</td>\n      <td>96.0</td>\n      <td>24.5</td>\n      <td>9.20</td>\n      <td>4.10</td>\n      <td>0.76</td>\n      <td>14.13</td>\n      <td>1.60</td>\n    </tr>\n  </tbody>\n</table>\n<p>177 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "#working relief\n",
    "import sklearn_relief as relief\n",
    "url = '/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/numeric datasets/wine/wine.data'\n",
    "df = pd.read_csv(url, index_col=False)\n",
    "X = df.iloc[: , 1:]\n",
    "Y = df.iloc[:, 0]\n",
    "r = relief.Relief(\n",
    "    n_features=8 # Choose the best 3 features\n",
    ") # Will run by default on all processors concurrently\n",
    "my_transformed_matrix = r.fit_transform(\n",
    "    X.values,\n",
    "    (Y.values)\n",
    ")\n",
    "pd.DataFrame(my_transformed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.33477065 6.        ]\n [0.32114068 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "150",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 150 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-39b864c6c6c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mreliefF_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReliefF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#ReliefF as a default 'k' hyperparameter that is set to 100 by default (i.e. 100 nearest neighbors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreliefF_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/skrebate/relieff.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getMultiClassMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'All labels are of the same class.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/skrebate/relieff.py\u001b[0m in \u001b[0;36m_getMultiClassMap\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datalen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmcmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m                 \u001b[0mmcmap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 150"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skrebate import MultiSURF\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "#url = '/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/iris/iris.data'\n",
    "url = '/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/numeric datasets/wine/wine.data'\n",
    "\n",
    "d = custom_csv(url)\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "#X = iris.data  # we only take the first two features.\n",
    "#y = iris.target\n",
    "\n",
    "X = getindependentVariables(url)\n",
    "\n",
    "y = getLabels(url)\n",
    "\n",
    "y  = labels.astype('category')\n",
    "y = y.cat.codes\n",
    "\n",
    "reliefF_results = ReliefF().fit(X, y) #ReliefF as a default 'k' hyperparameter that is set to 100 by default (i.e. 100 nearest neighbors)\n",
    "print(reliefF_results)\n",
    "\n",
    "#Present results\n",
    "#header = X.columns.tolist()\n",
    "#features = header[0:len(header)-1]\n",
    "#names_scores = {'Names':features, 'Scores':reliefF_results.feature_importances_} \n",
    "#ns = pd.DataFrame(names_scores)\n",
    "#ns = ns.sort_values(by='Scores')\n",
    "#ns #Report sorted feature scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          0     1     2      3     4     5     6     7\n",
       "0    1050.0  3.40  1.05   4.38  1.28  0.26  2.76  2.65\n",
       "1    1185.0  3.17  1.03   5.68  2.81  0.30  3.24  2.80\n",
       "2    1480.0  3.45  0.86   7.80  2.18  0.24  3.49  3.85\n",
       "3     735.0  2.93  1.04   4.32  1.82  0.39  2.69  2.80\n",
       "4    1450.0  2.85  1.05   6.75  1.97  0.34  3.39  3.27\n",
       "..      ...   ...   ...    ...   ...   ...   ...   ...\n",
       "172   740.0  1.74  0.64   7.70  1.06  0.52  0.61  1.68\n",
       "173   750.0  1.56  0.70   7.30  1.41  0.43  0.75  1.80\n",
       "174   835.0  1.56  0.59  10.20  1.35  0.43  0.69  1.59\n",
       "175   840.0  1.62  0.60   9.30  1.46  0.53  0.68  1.65\n",
       "176   560.0  1.60  0.61   9.20  1.35  0.56  0.76  2.05\n",
       "\n",
       "[177 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1050.0</td>\n      <td>3.40</td>\n      <td>1.05</td>\n      <td>4.38</td>\n      <td>1.28</td>\n      <td>0.26</td>\n      <td>2.76</td>\n      <td>2.65</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1185.0</td>\n      <td>3.17</td>\n      <td>1.03</td>\n      <td>5.68</td>\n      <td>2.81</td>\n      <td>0.30</td>\n      <td>3.24</td>\n      <td>2.80</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1480.0</td>\n      <td>3.45</td>\n      <td>0.86</td>\n      <td>7.80</td>\n      <td>2.18</td>\n      <td>0.24</td>\n      <td>3.49</td>\n      <td>3.85</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>735.0</td>\n      <td>2.93</td>\n      <td>1.04</td>\n      <td>4.32</td>\n      <td>1.82</td>\n      <td>0.39</td>\n      <td>2.69</td>\n      <td>2.80</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1450.0</td>\n      <td>2.85</td>\n      <td>1.05</td>\n      <td>6.75</td>\n      <td>1.97</td>\n      <td>0.34</td>\n      <td>3.39</td>\n      <td>3.27</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>172</th>\n      <td>740.0</td>\n      <td>1.74</td>\n      <td>0.64</td>\n      <td>7.70</td>\n      <td>1.06</td>\n      <td>0.52</td>\n      <td>0.61</td>\n      <td>1.68</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>750.0</td>\n      <td>1.56</td>\n      <td>0.70</td>\n      <td>7.30</td>\n      <td>1.41</td>\n      <td>0.43</td>\n      <td>0.75</td>\n      <td>1.80</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>835.0</td>\n      <td>1.56</td>\n      <td>0.59</td>\n      <td>10.20</td>\n      <td>1.35</td>\n      <td>0.43</td>\n      <td>0.69</td>\n      <td>1.59</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>840.0</td>\n      <td>1.62</td>\n      <td>0.60</td>\n      <td>9.30</td>\n      <td>1.46</td>\n      <td>0.53</td>\n      <td>0.68</td>\n      <td>1.65</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>560.0</td>\n      <td>1.60</td>\n      <td>0.61</td>\n      <td>9.20</td>\n      <td>1.35</td>\n      <td>0.56</td>\n      <td>0.76</td>\n      <td>2.05</td>\n    </tr>\n  </tbody>\n</table>\n<p>177 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "#working relief\n",
    "import sklearn_relief as relief\n",
    "url = '/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/numeric datasets/wine/wine.data'\n",
    "df = pd.read_csv(url, index_col=False)\n",
    "X = df.iloc[: , 1:]\n",
    "Y = df.iloc[:, 0]\n",
    "r = relief.ReliefF(\n",
    "    n_features=8 # Choose the best 3 features\n",
    ") # Will run by default on all processors concurrently\n",
    "my_transformed_matrix = r.fit_transform(\n",
    "    X.values,\n",
    "    (Y.values)\n",
    ")\n",
    "pd.DataFrame(my_transformed_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "labels = getLabels(url)\n",
    "\n",
    "\n",
    "oe_style = OneHotEncoder()\n",
    "oe_results = oe_style.fit_transform([labels.values])\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "df = pd.DataFrame\n",
    "ord_enc = OrdinalEncoder()\n",
    "make_code = ord_enc.fit_transform([labels])\n",
    "print(make_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'(slice(None, None, None), 0)' is an invalid key",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b47609fe2ad4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfcbf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcbf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/fcbf.py\u001b[0m in \u001b[0;36mfcbf\u001b[0;34m(X, y, thresh)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mPerform\u001b[0m \u001b[0mFast\u001b[0m \u001b[0mCorrelation\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mBased\u001b[0m \u001b[0mFilter\u001b[0m \u001b[0msolution\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mFCBF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mParameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mD\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/fcbf.py\u001b[0m in \u001b[0;36mc_correlation\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mA\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0md\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mSU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mflag\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0mRepresents\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mneeds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mremoved\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0mcasted_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2900\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), 0)' is an invalid key"
     ]
    }
   ],
   "source": [
    "import fcbf\n",
    "url = '/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/numeric datasets/wine/wine.data'\n",
    "df = pd.read_csv(url, index_col=False)\n",
    "X = df.iloc[: , 1:]\n",
    "Y = df.iloc[:, 0]\n",
    "t = 0.05\n",
    "sub = fcbf.fcbf(X,Y,t)\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.33477065 6.        ]\n [0.32114068 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.33477065 6.        ]\n [0.32114068 0.        ]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   0   1   2   3   4   5   6   7   8   9   10  11  12\n0  E1   1   3   0   1   0   1   2   2   3   3   2   7\n1  E2   0  25   0   1   2   1   2   2   3   3   2   7\n2  E3   0  39   0   0   0   0   2   2   3   0   2   7\n3  E5   0  29   0   1   2   1   2   2   3   3   2   7\n4  E6   1  23   0   1   0   1   2   2   3   0   2   7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Using .fit_transform function to fit label\n",
    "# encoder and return encoded label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}