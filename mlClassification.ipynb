{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": ".deeplearningclass",
   "display_name": ".deeplearningClass",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    " #converting string categorical value to numeric categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#feature selection\n",
    "from sklearn import svm\n",
    "\n",
    "from mrmr import mrmr_classif\n",
    "from info_gain import info_gain\n",
    "from c45 import C45\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#external files\n",
    "import fc\n",
    "import testrelief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import accuracy_score, log_loss\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _readCSVFile(filePath):\n",
    "        with open(filePath, 'r', newline='',  encoding='utf-8') as csvfile:\n",
    "            has_header = csv.Sniffer().has_header(csvfile.readline())\n",
    "            csvfile.seek(0)  # Rewind.\n",
    "            dialect = csv.Sniffer().sniff(csvfile.read(), delimiters=';,\\t')\n",
    "            csvfile.seek(0) \n",
    "            reader = csv.reader(csvfile, dialect)\n",
    "            if(has_header):\n",
    "                next(reader)  # Skip header row.\n",
    "            dataset = pd.DataFrame(reader)\n",
    "        return dataset\n",
    "        #print(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _readExcel(filePath):\n",
    "    dataset = pd.read_excel(filePath)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_csv(fname):\n",
    "    if fname.endswith((\".data\", \".csv\")):\n",
    "        return _readCSVFile(fname)\n",
    "    elif fname.endswith((\".xlsx\", \".xls\")):\n",
    "        return _readExcel(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _assumption1categorical(df):\n",
    "    likely_cat = []\n",
    "    for idx, var in enumerate(df.columns):\n",
    "        if(1.*df[var].nunique()/df[var].count() < 0.05): #or some other threshold\n",
    "            likely_cat.append(idx)\n",
    "    return likely_cat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _assumption2categorical(df):\n",
    "    top_n = 10 \n",
    "    likely_cat = []\n",
    "    for idx, var in enumerate(df.columns):\n",
    "        if(1.*df[var].value_counts(normalize=True).head(top_n).sum() > 0.8): #or some other threshold\n",
    "            likely_cat.append(idx)\n",
    "    return likely_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertstrtointcategory(df): \n",
    "    le = LabelEncoder()\n",
    "    ass1 = _assumption1categorical(df) \n",
    "    ass2 = _assumption2categorical(df)\n",
    "\n",
    "    #extract only columns that belong to \n",
    "    commonidx = (list(set(ass1) | set(ass2)))\n",
    "\n",
    "    for i in commonidx:\n",
    "        df.iloc[:,i] = le.fit_transform(df.iloc[:,i])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabels(dataset):\n",
    "    try:\n",
    "        flag = 0\n",
    "        #dataset = custom_csv(filePath)\n",
    "        #dataset = pd.read_csv(\"/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/iris/iris.data\")\n",
    "        n = dataset.iloc[:, -1].nunique(dropna=False)\n",
    "        perc = dataset.iloc[:, -1].value_counts(normalize=True)*100\n",
    "        if(len(perc) > len(dataset.iloc[:, 0].value_counts(normalize=True)*100)):  #checking whether 1st column is label\n",
    "            n=dataset.iloc[:, 0].nunique(dropna=False)\n",
    "            flag = 1\n",
    "        if(flag == 1):\n",
    "            return dataset.iloc[:, 0]\n",
    "        else:\n",
    "            return dataset.iloc[:,-1]\n",
    "    except:\n",
    "        print(\"Can not read last column items for\", filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getindependentVariables(dataset):\n",
    "    try:\n",
    "        flag = 0\n",
    "        #dataset = custom_csv(filePath)\n",
    "        n = dataset.iloc[:, -1].nunique(dropna=False)\n",
    "        perc = dataset.iloc[:, -1].value_counts(normalize=True)*100\n",
    "        if(len(perc) > len(dataset.iloc[:, 0].value_counts(normalize=True)*100)):  #checking whether 1st column is label\n",
    "            n=dataset.iloc[:, 0].nunique(dropna=False)\n",
    "            flag = 1\n",
    "        if(flag == 1):\n",
    "            return dataset.iloc[:, 1:]\n",
    "        else:\n",
    "            return dataset.iloc[:,:-1]\n",
    "    except:\n",
    "        print(\"Can not independent variabless for\", filePath)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectFeatures(X, impFeatures, threshold):\n",
    "    X_new = pd.DataFrame()\n",
    "    for idx, value in enumerate(impFeatures):\n",
    "        if(value > threshold):\n",
    "            X_new = pd.concat((X_new, X.iloc[:, idx]), axis=1)\n",
    "    return X_new    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutualInfo(X,Y):\n",
    "    return mutual_info_classif(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gainRatio(X,Y):\n",
    "    info_gain_ratio_values = []\n",
    "    for idx, col in X.iteritems():\n",
    "        info_gain_ratio_values.append(info_gain.info_gain_ratio(col.values, Y.values.tolist()))\n",
    "    return info_gain_ratio_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniqueClasses(Y):\n",
    "    return len(Y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reliefFeature(X, Y):\n",
    "    X=np.array(X)\n",
    "    print(type(X))\n",
    "    X = X.astype(np.float)\n",
    "    print(type(Y.values))\n",
    "    r = testrelief.Relief(n_features=(X.shape[1]-1) ) # Will run by default on all processors concurrently\n",
    "    my_transformed_matrix = r.fit_transform(X,Y.values)\n",
    "    return r.w_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4d100e2d0b35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#report should be dataset specific - each output file is for a single dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmacro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"avg,weighted\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"avg,\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CA,\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FS,\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"->\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"such\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"4*9\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"in\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"each\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "#report should be dataset specific - each output file is for a single dataset\n",
    "\n",
    ",0,1,2,accuracy,macro avg,weighted avg, CA, FS, %features  -> such 4*9 rows in each file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcbf_features(X,Y):\n",
    "    return fc.fcbf(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(clf, X,Y, fs):\n",
    "    #dataset = custom_csv(fileName)\n",
    "    #X = getindependentVariables(dataset)\n",
    "    #Y = getLabels(dt)\n",
    "    if(fs == \"MI\"):\n",
    "      impF = mutualInfo(X,Y)\n",
    "    elif(fs == \"GR\"):\n",
    "      impF = gainRatio(X,Y)\n",
    "    elif(fs == \"mrmr\"):\n",
    "      impF = mrmr_classif(X, Y, K = 10)\n",
    "    elif(fs == \"fcbf\"):\n",
    "      impF = fcbf_features(X,Y)\n",
    "    elif(fs == \"relief\"):\n",
    "      impF =  reliefFeature(X,Y)\n",
    "    X_new = selectFeatures(X, impF, 0.368)\n",
    "    if(len(X_new) == 0 ):\n",
    "        X_new = selectFeatures(X, impF, np.mean(impF))\n",
    "    print(len(X_new), len(Y))  # add this as a feature ; one of the evaluation criteria\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X_new,Y,test_size=0.25,random_state=0)\n",
    "    neighbors = uniqueClasses(Y)\n",
    "    aName = [\"a_\"+str(x) for x in range(X_new.shape[1])]\n",
    "    if(clf.__class__.__name__==\"C45\"):\n",
    "      aName = [\"a_\"+str(x) for x in range(X_new.shape[1])]\n",
    "      clf.fit(X_train,y_train, aName)\n",
    "    else:\n",
    "      clf.fit(X_train, y_train)\n",
    "    y_pred= clf.predict(X_test)\n",
    "    target_names = (list(range(uniqueClasses(Y))))\n",
    "    for index, item in enumerate(target_names):\n",
    "      target_names[index] = str(item)\n",
    "   # TN = cnf_matrix.values.sum() - (FP + FN + TP) \n",
    "    #tp, fn, fp, tn = metrics.confusion_matrix(y_test, y_pred, labels = getLabels(filePath)).ravel()\n",
    "    report = classification_report(y_test, y_pred,  target_names=target_names, output_dict=True)\n",
    "    return (report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "wine.data\n",
      "----------------------\n",
      "GaussianNB\n",
      "MI\n",
      "177 177\n",
      "*******DONE*********\n",
      "GR\n",
      "177 177\n",
      "*******DONE*********\n",
      "mrmr\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.82it/s]\n",
      "177 177\n",
      "*******DONE*********\n",
      "fcbf\n",
      "177 177\n",
      "*******DONE*********\n",
      "relief\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "177 177\n",
      "*******DONE*********\n",
      "SVC\n",
      "MI\n",
      "177 177\n",
      "*******DONE*********\n",
      "GR\n",
      "177 177\n",
      "*******DONE*********\n",
      "mrmr\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.13it/s]\n",
      "177 177\n",
      "*******DONE*********\n",
      "fcbf\n",
      "177 177\n",
      "*******DONE*********\n",
      "relief\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "177 177\n",
      "*******DONE*********\n",
      "C45\n",
      "MI\n",
      "177 177\n",
      "*******DONE*********\n",
      "GR\n",
      "177 177\n",
      "*******DONE*********\n",
      "mrmr\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.10it/s]\n",
      "177 177\n",
      "*******DONE*********\n",
      "fcbf\n",
      "177 177\n",
      "*******DONE*********\n",
      "relief\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "177 177\n",
      "*******DONE*********\n",
      "KNeighborsClassifier\n",
      "MI\n",
      "177 177\n",
      "*******DONE*********\n",
      "GR\n",
      "177 177\n",
      "*******DONE*********\n",
      "mrmr\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.25it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]177 177\n",
      "*******DONE*********\n",
      "fcbf\n",
      "177 177\n",
      "*******DONE*********\n",
      "relief\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "177 177\n",
      "*******DONE*********\n",
      "iris.data\n",
      "----------------------\n",
      "GaussianNB\n",
      "MI\n",
      "149 149\n",
      "*******DONE*********\n",
      "GR\n",
      "149 149\n",
      "*******DONE*********\n",
      "mrmr\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.50it/s]149 149\n",
      "*******DONE*********\n",
      "fcbf\n",
      "149 149\n",
      "*******DONE*********\n",
      "relief\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "149 149\n",
      "*******DONE*********\n",
      "SVC\n",
      "MI\n",
      "149 149\n",
      "*******DONE*********\n",
      "GR\n",
      "149 149\n",
      "*******DONE*********\n",
      "mrmr\n",
      "\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.46it/s]\n",
      "149 149\n",
      "*******DONE*********\n",
      "fcbf\n",
      "149 149\n",
      "*******DONE*********\n",
      "relief\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "149 149\n",
      "*******DONE*********\n",
      "C45\n",
      "MI\n",
      "149 149\n",
      "*******DONE*********\n",
      "GR\n",
      "149 149\n",
      "*******DONE*********\n",
      "mrmr\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.47it/s]\n",
      "149 149\n",
      "*******DONE*********\n",
      "fcbf\n",
      "149 149\n",
      "*******DONE*********\n",
      "relief\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "149 149\n",
      "*******DONE*********\n",
      "KNeighborsClassifier\n",
      "MI\n",
      "149 149\n",
      "*******DONE*********\n",
      "GR\n",
      "149 149\n",
      "*******DONE*********\n",
      "mrmr\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.46it/s]149 149\n",
      "*******DONE*********\n",
      "fcbf\n",
      "149 149\n",
      "*******DONE*********\n",
      "relief\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "149 149\n",
      "*******DONE*********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [ \n",
    "GaussianNB(), \n",
    "svm.SVC(kernel='linear', random_state=0),\n",
    "C45()\n",
    "]\n",
    "\n",
    "listofFiles={}\n",
    "classificationPerfomance={}\n",
    "featureAlgo = [\"MI\",\"GR\",\"mrmr\",\"fcbf\",\"relief\"]\n",
    "for path, subdirs, files in os.walk(os.getcwd()+'/datasets/test/'):\n",
    "    for name in files:\n",
    "        if name.endswith((\".data\", \".csv\", \".xlsx\", \".xls\")):\n",
    "            listofFiles[name]=os.path.join(path, name)\n",
    "\n",
    "for eachFile in listofFiles:\n",
    "    print(eachFile)\n",
    "    print(\"----------------------\")\n",
    "    classificationPerfomance = {}\n",
    "    dataset = custom_csv(listofFiles[eachFile])\n",
    "    dataset = convertstrtointcategory(dataset)\n",
    "    X = getindependentVariables(dataset)\n",
    "    Y = getLabels(dataset)\n",
    "    n = uniqueClasses(Y)\n",
    "    classifiers.append(KNeighborsClassifier(n))\n",
    "    for clf in classifiers:\n",
    "        name = clf.__class__.__name__\n",
    "        print(name)\n",
    "        classificationPerfomance[name] = {}\n",
    "        for eachFSAlgo in featureAlgo:\n",
    "            print(eachFSAlgo)\n",
    "            classificationPerfomance[name][eachFSAlgo] = {}\n",
    "            perfMetrics = classify(clf, X,Y, eachFSAlgo)\n",
    "            print(\"*******DONE*********\")\n",
    "            classificationPerfomance[name][eachFSAlgo] = (perfMetrics)\n",
    "    classifiers.pop(-1)\n",
    "    outfile =  os.path.splitext(eachFile)[0]+\".json\"\n",
    "\n",
    "    with open(outfile,\"w\") as f:\n",
    "    #dataAccuracy = dataAccuracy.to_json()\n",
    "        json.dump(classificationPerfomance,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile =  os.path.splitext(eachFile)[0]+\".json\"\n",
    "\n",
    "with open(outfile,\"w\") as f:\n",
    "    #classificationPerfomance = classificationPerfomance.to_json()\n",
    "    #pd.DataFrame(report).to_csv('sample.csv')\n",
    "\n",
    "    json.dump,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(classificationPerfomance)\n",
    "pd.DataFrame(classificationPerfomance).to_csv('sample1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.9555555555555556\n                   1      2         3  accuracy  macro avg  weighted avg\nprecision   1.000000   0.95  0.900000  0.955556   0.950000      0.957778\nrecall      0.937500   0.95  1.000000  0.955556   0.962500      0.955556\nf1-score    0.967742   0.95  0.947368  0.955556   0.955037      0.955782\nsupport    16.000000  20.00  9.000000  0.955556  45.000000     45.000000\n  Unnamed: 0                                         GaussianNB  \\\n0         GR  {'0': {'precision': 1.0, 'recall': 1.0, 'f1-sc...   \n1       mrmr  {'0': {'precision': 1.0, 'recall': 1.0, 'f1-sc...   \n2       fcbf  {'0': {'precision': 1.0, 'recall': 0.928571428...   \n3     relief  {'0': {'precision': 1.0, 'recall': 1.0, 'f1-sc...   \n\n                                                 SVC  \\\n0  {'0': {'precision': 1.0, 'recall': 1.0, 'f1-sc...   \n1  {'0': {'precision': 1.0, 'recall': 1.0, 'f1-sc...   \n2  {'0': {'precision': 1.0, 'recall': 0.928571428...   \n3  {'0': {'precision': 1.0, 'recall': 1.0, 'f1-sc...   \n\n                                                 C45  \\\n0  {'0': {'precision': 0.9333333333333333, 'recal...   \n1  {'0': {'precision': 1.0, 'recall': 1.0, 'f1-sc...   \n2  {'0': {'precision': 1.0, 'recall': 0.857142857...   \n3  {'0': {'precision': 0.9333333333333333, 'recal...   \n\n                                KNeighborsClassifier  \n0  {'0': {'precision': 1.0, 'recall': 1.0, 'f1-sc...  \n1  {'0': {'precision': 1.0, 'recall': 1.0, 'f1-sc...  \n2  {'0': {'precision': 1.0, 'recall': 0.928571428...  \n3  {'0': {'precision': 1.0, 'recall': 1.0, 'f1-sc...  \n"
     ]
    }
   ],
   "source": [
    "#working column append n classification report\n",
    "url =\"/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/test/1. Wine/wine.data\"\n",
    "df = custom_csv(url)\n",
    "X = getindependentVariables(df)\n",
    "Y = getLabels(df)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=0)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "#pd.DataFrame(report).to_csv('sample1.csv')\n",
    "print(pd.DataFrame(report))\n",
    "list_of_str = ['First', 'Second', 'Third', 'Fourth']\n",
    "tail_len = 4\n",
    "\n",
    "# The two steps in the description\n",
    "n_rows = sum(1 for row in open('sample1.csv', 'r'))\n",
    "df = pd.read_csv('sample1.csv', skiprows=range(1, n_rows - tail_len))\n",
    "df_rest  = pd.read_csv('sample1.csv', skiprows=range(tail_len, n_rows))\n",
    "\n",
    "print(df)\n",
    "clsss = 'KNN'\n",
    "percFeatures = 12\n",
    "FSA = 'qwe'\n",
    "df['class']=clsss\n",
    "df['percF'] = percFeatures\n",
    "df['FS'] = FSA\n",
    "df\n",
    "f = []\n",
    "pd.concat([df_rest, df]).to_csv('sampe2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'aN'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-df236146133f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC45\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrNames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Accuracy: {clf.score(X_test, y_test)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'aN'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dataset = readCSVFile(\"/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/numeric datasets/wine/wine.data\")\n",
    "#datasethead()\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data_banknote_authentication.csv\nheart_failure_clinical_records_datase.csv\nwine.data\nLasVegasTripAdvisorReviews-Dataset.csv\niris.data\nglass.data\nbank-full.csv\nHCV-Egy-Data2.csv\n"
     ]
    }
   ],
   "source": [
    "for path, subdirs, files in os.walk(os.getcwd()+'/datasets/numeric datasets'):\n",
    "    for name in files:\n",
    "        if name.endswith((\".data\", \".csv\", \".xlsx\")):\n",
    "            listofFiles[name]=os.path.join(path, name)\n",
    "for eachFile in listofFiles:\n",
    "    print(eachFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   0          1          2          3  accuracy   macro avg  \\\n",
       "precision   0.174419   0.265306   0.202532   0.285714  0.236311    0.231993   \n",
       "recall      0.178571   0.135417   0.202532   0.431818  0.236311    0.237084   \n",
       "f1-score    0.176471   0.179310   0.202532   0.343891  0.236311    0.225551   \n",
       "support    84.000000  96.000000  79.000000  88.000000  0.236311  347.000000   \n",
       "\n",
       "           weighted avg  \n",
       "precision      0.234188  \n",
       "recall         0.236311  \n",
       "f1-score       0.225648  \n",
       "support      347.000000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>accuracy</th>\n      <th>macro avg</th>\n      <th>weighted avg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>precision</th>\n      <td>0.174419</td>\n      <td>0.265306</td>\n      <td>0.202532</td>\n      <td>0.285714</td>\n      <td>0.236311</td>\n      <td>0.231993</td>\n      <td>0.234188</td>\n    </tr>\n    <tr>\n      <th>recall</th>\n      <td>0.178571</td>\n      <td>0.135417</td>\n      <td>0.202532</td>\n      <td>0.431818</td>\n      <td>0.236311</td>\n      <td>0.237084</td>\n      <td>0.236311</td>\n    </tr>\n    <tr>\n      <th>f1-score</th>\n      <td>0.176471</td>\n      <td>0.179310</td>\n      <td>0.202532</td>\n      <td>0.343891</td>\n      <td>0.236311</td>\n      <td>0.225551</td>\n      <td>0.225648</td>\n    </tr>\n    <tr>\n      <th>support</th>\n      <td>84.000000</td>\n      <td>96.000000</td>\n      <td>79.000000</td>\n      <td>88.000000</td>\n      <td>0.236311</td>\n      <td>347.000000</td>\n      <td>347.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "perfMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'aN'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-df236146133f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC45\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrNames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Accuracy: {clf.score(X_test, y_test)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'aN'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from c45 import C45\n",
    "d=custom_csv('/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/working/1. Wine/wine.data')\n",
    "X = getindependentVariables(d)\n",
    "Y = getLabels(d)\n",
    "\n",
    "aName = [\"a_\"+str(x) for x in range(X.shape[1])]\n",
    "\n",
    "iris = load_iris()\n",
    "#X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.5)\n",
    "#clf = C45(attrNames=iris.feature_names)\n",
    "\n",
    "impF = gainRatio(X,Y)\n",
    "X_new = selectFeatures(X, impF, 0.368)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_new,Y,test_size=0.25,random_state=0)\n",
    "aName = [\"a_\"+str(x) for x in range(X_new.shape[1])]\n",
    "clf = C45(attrNames=aName)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(f'Accuracy: {clf.score(X_test, y_test)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"dataaccuracy.json\",\"w\") as f:\n",
    "    #dataAccuracy = dataAccuracy.to_json()\n",
    "    json.dump(dataAccuracy,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'{}'"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "json.dumps(dataAccuracy, indent=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-29-0f41813719f4>, line 13)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-0f41813719f4>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    perfMetrics =\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "listofFiles={}\n",
    "classificationPerfomance={}\n",
    "i=1\n",
    "j=1\n",
    "\n",
    "classificationAlgo = {'knn', 'c45', 'nb', 'svm'}\n",
    "featureAlgo = {'relief', 'relieff', 'ig', 'gr', 'fcbf', 'mrmr', 'qbb', 'focus', 'sc'}\n",
    "for path, subdirs, files in os.walk(os.getcwd()+'/datasets/numeric datasets'):\n",
    "    for name in files:\n",
    "        if name.endswith((\".data\", \".csv\", \".xlsx\")):\n",
    "            listofFiles[name]=os.path.join(path, name)\n",
    "\n",
    "perfMetrics =            \n",
    "for eachFile in listofFiles:\n",
    "    classificationPerfomance[eachFile] = {}\n",
    "    for eachClassAlgo in classificationAlgo:\n",
    "        j+=1\n",
    "        classificationPerfomance[eachFile][eachClassAlgo] = {}\n",
    "        for eachFSAlgo in featureAlgo:\n",
    "            fs = \"FS\"+str(i)\n",
    "            classificationPerfomance[eachFile][eachClassAlgo][eachFSAlgo] = {}\n",
    "            i+=1\n",
    "            if(eachClassAlgo == \"kNN\"):\n",
    "                perfMetrics = classifyKNN(listofFiles[eachFile], eachFSAlgo)\n",
    "            #classificationPerfomance[eachFile]['acc'] = 1\n",
    "\n",
    "        i=1\n",
    "    j=1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "\n",
    "dataset = pd.read_csv(\"/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/numeric datasets/heart failure/heart_failure_clinical_records_dataset.csv\")\n",
    "Y = dataset.iloc[:, :1]\n",
    "X = dataset.iloc[:, 1:]\n",
    "#Y = getLabels(\"/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/iris/iris.data\")\n",
    "\n",
    "importantFeaures = mutual_info_classif(X, Y)\n",
    "print((importantFeaures))\n",
    "\n",
    "X_new = SelectPercentile(mutual_info_classif, percentile=70).fit_transform(X, Y)\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=0)\n",
    "\n",
    "fit = model.fit(X_train, y_train)\n",
    "\n",
    "print(X_new.shape)\n",
    "print(X.shape)\n",
    "y_red=fit.predict(X_test)\n",
    "# import the metrics class\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_red)\n",
    "cnf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=3,p=2,metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(y_test,y_pred, average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifaction_report_csv(report):\n",
    "    report_data = []\n",
    "    lines = report.split('\\n')\n",
    "    for line in lines[2:-3]:\n",
    "        row = {}\n",
    "        row_data = line.split('      ')\n",
    "        row['class'] = row_data[0]\n",
    "        row['precision'] = float(row_data[1])\n",
    "        row['recall'] = float(row_data[2])\n",
    "        row['f1_score'] = float(row_data[3])\n",
    "        row['support'] = float(row_data[4])\n",
    "        report_data.append(row)\n",
    "    dataframe = pd.DataFrame.from_dict(report_data)\n",
    "    dataframe.to_csv('classification_report.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = '/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/numeric datasets/wine/wine.data'\n",
    "\n",
    "\n",
    "data = pd.read_csv(url,low_memory=False)\n",
    "x_1 = getindependentVariables(url)\n",
    "data_dia = getLabels(url)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_1, data_dia, test_size=0.3, random_state=42)\n",
    "classifiers = [ \n",
    "KNeighborsClassifier(3),\n",
    "DecisionTreeClassifier(),\n",
    "RandomForestClassifier(),\n",
    "AdaBoostClassifier(),\n",
    "GradientBoostingClassifier(),\n",
    "GaussianNB(),\n",
    "LinearDiscriminantAnalysis() \n",
    "]\n",
    "\n",
    "# Logging for Visual Comparison\n",
    "log_cols = [\"Classifier\", \"Accuracy\", \"Log Loss\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(x_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    print(\"=\" * 30)\n",
    "    print(name)\n",
    "\n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(x_test)\n",
    "    acc = accuracy_score(y_test, train_predictions)\n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "\n",
    "    train_predictions = clf.predict_proba(x_test)\n",
    "    ll = log_loss(y_test, train_predictions)\n",
    "    print(\"Log Loss: {}\".format(ll))\n",
    "\n",
    "    #log_entry = pd.DataFrame([[name, acc * 100, ll]], columns=log_cols)\n",
    "    #log = log.append(log_entry)\n",
    "    #report = classification_report(y_test, train_predictions)\n",
    "    #print(\"log:\",log)\n",
    "    #print(\"=\" * 30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mrmr'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b5f51ac59878>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmrmr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmrmr_classif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mrmr'"
     ]
    }
   ],
   "source": [
    "from mrmr import mrmr_classif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'c45'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-aa2201a74085>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mc45\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mC45\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0miris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC45\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrNames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'c45'"
     ]
    }
   ],
   "source": [
    "from c45 import C45\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "clf = C45(attrNames=iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.9777777777777777\nNumber of mislabeled points out of a total 45 points : 1\n              0          1         2  accuracy  macro avg  weighted avg\nprecision   1.0   1.000000  0.888889  0.977778   0.962963      0.980247\nrecall      1.0   0.952381  1.000000  0.977778   0.984127      0.977778\nf1-score    1.0   0.975610  0.941176  0.977778   0.972262      0.978160\nsupport    16.0  21.000000  8.000000  0.977778  45.000000     45.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "X = getindependentVariables(url)\n",
    "Y = getLabels(url)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=0)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "target_names = (list(range(uniqueClasses(Y))))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (y_test != y_pred).sum()))\n",
    "report = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "pd.DataFrame(report).to_csv('sample.csv')\n",
    "print(pd.DataFrame(report))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column_in_csv_2(input_file, output_file, transform_row, tansform_column_names):\n",
    "    \"\"\" Append a column in existing csv using csv.reader / csv.writer classes\"\"\"\n",
    "    # Open the input_file in read mode and output_file in write mode\n",
    "    with open(input_file, 'r') as read_obj, \\\n",
    "            open(output_file, 'w', newline='') as write_obj:\n",
    "        # Create a DictReader object from the input file object\n",
    "        dict_reader = DictReader(read_obj)\n",
    "        # Get a list of column names from the csv\n",
    "        field_names = dict_reader.fieldnames\n",
    "        # Call the callback function to modify column name list\n",
    "        tansform_column_names(field_names)\n",
    "        # Create a DictWriter object from the output file object by passing column / field names\n",
    "        dict_writer = DictWriter(write_obj, field_names)\n",
    "        # Write the column names in output csv file\n",
    "        dict_writer.writeheader()\n",
    "        # Read each row of the input csv file as dictionary\n",
    "        for row in dict_reader:\n",
    "            # Modify the dictionary / row by passing it to the transform function (the callback)\n",
    "            transform_row(row, dict_reader.line_num)\n",
    "            # Write the updated dictionary or row to the output file\n",
    "            dict_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.9777777777777777\n              0          1         2  accuracy  macro avg  weighted avg\nprecision   1.0   1.000000  0.888889  0.977778   0.962963      0.980247\nrecall      1.0   0.952381  1.000000  0.977778   0.984127      0.977778\nf1-score    1.0   0.975610  0.941176  0.977778   0.972262      0.978160\nsupport    16.0  21.000000  8.000000  0.977778  45.000000     45.000000\n  Unnamed: 0     0          1         2  accuracy  macro avg  weighted avg\n0  precision   1.0   1.000000  0.888889  0.977778   0.962963      0.980247\n1     recall   1.0   0.952381  1.000000  0.977778   0.984127      0.977778\n2   f1-score   1.0   0.975610  0.941176  0.977778   0.972262      0.978160\n3    support  16.0  21.000000  8.000000  0.977778  45.000000     45.000000\n"
     ]
    }
   ],
   "source": [
    "#working column append n classification report\n",
    "\n",
    "X = getindependentVariables(url)\n",
    "Y = getLabels(url)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=0)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "report = classification_report(y_test, y_pred,  target_names=target_names, output_dict=True)\n",
    "#pd.DataFrame(report).to_csv('sample1.csv')\n",
    "print(pd.DataFrame(report))\n",
    "list_of_str = ['First', 'Second', 'Third', 'Fourth']\n",
    "tail_len = 4\n",
    "\n",
    "# The two steps in the description\n",
    "n_rows = sum(1 for row in open('sample1.csv', 'r'))\n",
    "df = pd.read_csv('sample1.csv', skiprows=range(1, n_rows - tail_len))\n",
    "df_rest  = pd.read_csv('sample1.csv', skiprows=range(tail_len, n_rows))\n",
    "\n",
    "print(df)\n",
    "clsss = 'KNN'\n",
    "percFeatures = 12\n",
    "FSA = 'qwe'\n",
    "df['class']=clsss\n",
    "df['percF'] = percFeatures\n",
    "df['FS'] = FSA\n",
    "df\n",
    "f = []\n",
    "pd.concat([df_rest, df]).to_csv('sampe2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = '/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/working/1. Wine/wine.data'\n",
    "d = custom_csv(url)\n",
    "\n",
    "X = getindependentVariables(d)\n",
    "Y = getLabels(d)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=0)\n",
    "neighbors = uniqueClasses(Y)\n",
    "attrN= ([str(p) for p in range(0, neighbors)])\n",
    "clf = C45(pathToNames=attrN)\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.8933333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from c45 import C45\n",
    "\n",
    "iris = load_iris()\n",
    "clf = C45(attrNames=iris.feature_names)\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.5)\n",
    "clf.fit(X_train, y_train)\n",
    "from c45 import C45\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'c45'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-15724f7a063e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mc45\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'c45'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/numeric datasets/1. Wine/wine.data'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-db77b1e72b64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn_relief\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrelief\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/numeric datasets/1. Wine/wine.data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/numeric datasets/1. Wine/wine.data'"
     ]
    }
   ],
   "source": [
    "#working relief\n",
    "import sklearn_relief as relief\n",
    "url = '/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/numeric datasets/1. Wine/wine.data'\n",
    "df = pd.read_csv(url, index_col=False)\n",
    "X = df.iloc[: , 1:]\n",
    "Y = df.iloc[:, 0]\n",
    "r = relief.Relief(\n",
    "    n_features=3 # Choose the best 3 features\n",
    ") # Will run by default on all processors concurrently\n",
    "my_transformed_matrix = r.fit_transform(\n",
    "    X.values,\n",
    "    (Y.values)\n",
    ")\n",
    "pd.DataFrame(my_transformed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Relief()\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-5fe6b6ac7757>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_transformed_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DataFrame constructor not properly called!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "#working relief\n",
    "import sklearn_relief as relief\n",
    "url = '/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/working/1. Wine/wine.data'\n",
    "df = pd.read_csv(url, index_col=False)\n",
    "X = df.iloc[: , 1:]\n",
    "Y = df.iloc[:, 0]\n",
    "r = relief.Relief(\n",
    "    n_features=8 # Choose the best 3 features\n",
    ") # Will run by default on all processors concurrently\n",
    "my_transformed_matrix = r.fit_transform(\n",
    "    X.values,\n",
    "    (Y.values)\n",
    ")\n",
    "print(r)\n",
    "pd.DataFrame(my_transformed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.33477065 6.        ]\n [0.32114068 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   0  1     2  3   4  5          6    7    8  9  10 11 12\n0  75  0   582  0  20  1     265000  1.9  130  1  0  4  1\n1  55  0  7861  0  38  0  263358.03  1.1  136  1  0  6  1\n2  65  0   146  0  20  0     162000  1.3  129  1  1  7  1\n3  50  1   111  0  20  0     210000  1.9  137  1  0  7  1\n4  65  1   160  1  20  0     327000  2.7  116  0  0  8  1\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-e396d20bb24c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReliefF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_features_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/skrebate/relieff.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# Number of missing data values in predictor variable matrix.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_missing_data_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \"\"\"Assign internal headers for the features (scikit-learn does not accept external headers from dataset):\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skrebate import MultiSURF\n",
    "from skrebate import ReliefF\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "#url = '/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/iris/iris.data'\n",
    "url = '/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/working/2. Heart failure/heart_failure_clinical_records_dataset.csv'\n",
    "\n",
    "d = custom_csv(url)\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "#X = iris.data  # we only take the first two features.\n",
    "#y = iris.target\n",
    "\n",
    "print(d.head())\n",
    "X = getindependentVariables(d)\n",
    "\n",
    "y = getLabels(d)\n",
    "\n",
    "#y  = labels.astype('category')\n",
    "#y = y.cat.codes\n",
    "\n",
    "fs = ReliefF()\n",
    "fs.fit(X, y)\n",
    "print(fs.top_features_)\n",
    "\n",
    "#for feature_name, feature_score in zip(d.columns, fs.feature_importances_):\n",
    " #   print(feature_name, '\\t', feature_score)\n",
    "\n",
    "\n",
    "#reliefF_results = ReliefF().fit(X, y) #ReliefF as a default 'k' hyperparameter that is set to 100 by default (i.e. 100 nearest neighbors)\n",
    "#print(reliefF_results)\n",
    "\n",
    "#Present results\n",
    "#header = X.columns.tolist()\n",
    "#features = header[0:len(header)-1]\n",
    "#names_scores = {'Names':features, 'Scores':reliefF_results.feature_importances_} \n",
    "#ns = pd.DataFrame(names_scores)\n",
    "#ns = ns.sort_values(by='Scores')\n",
    "#ns #Report sorted feature scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-e69d8d4eec10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReliefF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#for feature_name, feature_score in zip(genetic_data.drop('class', axis=1).columns,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/skrebate/relieff.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# Number of missing data values in predictor variable matrix.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_missing_data_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \"\"\"Assign internal headers for the features (scikit-learn does not accept external headers from dataset):\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from skrebate import ReliefF\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "genetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'\n",
    "                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.tsv.gz',\n",
    "                           sep='\\t', compression='gzip')\n",
    "\n",
    "#features, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values\n",
    "url = '/home/d19125691/Documents/Experiments/ontologyDCQ/onto-DCQ-FS/datasets/working/2. Heart failure/heart_failure_clinical_records_dataset.csv'\n",
    "\n",
    "d = custom_csv(url)\n",
    "\n",
    "features = getindependentVariables(d)\n",
    "\n",
    "labels = getLabels(d)\n",
    "\n",
    "\n",
    "# Make sure to compute the feature importance scores from only your training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels)\n",
    "\n",
    "fs = ReliefF()\n",
    "fs.fit(X_train, y_train)\n",
    "\n",
    "#for feature_name, feature_score in zip(genetic_data.drop('class', axis=1).columns,\n",
    " #                                      fs.feature_importances_):\n",
    "  #  print(feature_name, '\\t', feature_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(element) -> bool:\n",
    "    try:\n",
    "        float(element)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "        \n",
    "def greatestNegative(columnValues):\n",
    "    result = 0\n",
    "    for number in columnValues:\n",
    "        if(is_float(number)):\n",
    "            if(float(number) < 0):\n",
    "                if(float(number) < float(result)):\n",
    "                    result = number\n",
    "    return result\n",
    "\n",
    "def findmin(df):\n",
    "    result = []\n",
    "    for c in df:\n",
    "        result.append(greatestNegative(df[c]))\n",
    "    return min(result)\n",
    "\n",
    "def addMintoDF(df, minElement):\n",
    "    for c in df:\n",
    "        df[c] = pd.to_numeric(df[c]) + minElement\n",
    "    return df"
   ]
  }
 ]
}